optimizer_adam:
  _target_: tensorflow.keras.optimizers.Adam
  learning_rate: 1e-4

use_learning_rate_decay: True

decay_scheduler:
  _target_: tensorflow.keras.optimizers.schedules.ExponentialDecay
  initial_learning_rate: ${..optimizer.learning_rate}
  decay_steps: 2000
  decay_rate: 0.9
  staircase: True
